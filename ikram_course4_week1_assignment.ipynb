{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Data integration, Visualization and ETL\nI used 'train.csv' file where i have my dataset for training"
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_3c4c594765474e10870775abb04cbf2f = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='QoPFoBkCOcy5_z9sCxxIlro_taDDVczipnPs_wXceqeF',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_3c4c594765474e10870775abb04cbf2f.get_object(Bucket='defaultikram-donotdelete-pr-ht8dbkrt3n4iv5',Key='train.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n\nprint(type(df_data_1))",
            "execution_count": 142,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "<class 'pandas.core.frame.DataFrame'>\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.sql.types import *\n\n\nmySchema = StructType([ StructField(\"battery_power\", IntegerType(), True)\\\n\n                       ,StructField(\"blue\", IntegerType(), True)\\\n\n                       ,StructField(\"clock_speed\", DoubleType(), True)\\\n\n                       ,StructField(\"dual_sim\", IntegerType(), True)\\\n\n                       ,StructField(\"fc\", IntegerType(), True)\\\n\n                       ,StructField(\"four_g\", IntegerType(), True)\\\n\n                       ,StructField(\"int_memory\", IntegerType(), True)\\\n\n                       ,StructField(\"m_dep\", DoubleType(), True)\\\n\n                       ,StructField(\"mobile_wt\", IntegerType(), True)\\\n\n                       ,StructField(\"n_cores\", IntegerType(), True)\\\n\n                       ,StructField(\"pc\", IntegerType(), True)\\\n\n                       ,StructField(\"px_height\", IntegerType(), True)\\\n\n                       ,StructField(\"px_width\", IntegerType(), True)\\\n\n                       ,StructField(\"ram\", IntegerType(), True)\\\n\n                       ,StructField(\"sc_h\", IntegerType(), True)\\\n\n                       ,StructField(\"sc_w\", IntegerType(), True)\\\n\n                       ,StructField(\"talk_time\", IntegerType(), True)\\\n\n                       ,StructField(\"three_g\", IntegerType(), True)\\\n\n                       ,StructField(\"touch_screen\", IntegerType(), True)\\\n\n                       ,StructField(\"wifi\", IntegerType(), True)\\\n\n                       ,StructField(\"price_range\", IntegerType(), True)])",
            "execution_count": 143,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ndf = spark.createDataFrame(df_data_1,schema=mySchema)\ndf.show()\n",
            "execution_count": 144,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+\n|battery_power|blue|clock_speed|dual_sim| fc|four_g|int_memory|m_dep|mobile_wt|n_cores| pc|px_height|px_width| ram|sc_h|sc_w|talk_time|three_g|touch_screen|wifi|price_range|\n+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+\n|          842|   0|        2.2|       0|  1|     0|         7|  0.6|      188|      2|  2|       20|     756|2549|   9|   7|       19|      0|           0|   1|          1|\n|         1021|   1|        0.5|       1|  0|     1|        53|  0.7|      136|      3|  6|      905|    1988|2631|  17|   3|        7|      1|           1|   0|          2|\n|          563|   1|        0.5|       1|  2|     1|        41|  0.9|      145|      5|  6|     1263|    1716|2603|  11|   2|        9|      1|           1|   0|          2|\n|          615|   1|        2.5|       0|  0|     0|        10|  0.8|      131|      6|  9|     1216|    1786|2769|  16|   8|       11|      1|           0|   0|          2|\n|         1821|   1|        1.2|       0| 13|     1|        44|  0.6|      141|      2| 14|     1208|    1212|1411|   8|   2|       15|      1|           1|   0|          1|\n|         1859|   0|        0.5|       1|  3|     0|        22|  0.7|      164|      1|  7|     1004|    1654|1067|  17|   1|       10|      1|           0|   0|          1|\n|         1821|   0|        1.7|       0|  4|     1|        10|  0.8|      139|      8| 10|      381|    1018|3220|  13|   8|       18|      1|           0|   1|          3|\n|         1954|   0|        0.5|       1|  0|     0|        24|  0.8|      187|      4|  0|      512|    1149| 700|  16|   3|        5|      1|           1|   1|          0|\n|         1445|   1|        0.5|       0|  0|     0|        53|  0.7|      174|      7| 14|      386|     836|1099|  17|   1|       20|      1|           0|   0|          0|\n|          509|   1|        0.6|       1|  2|     1|         9|  0.1|       93|      5| 15|     1137|    1224| 513|  19|  10|       12|      1|           0|   0|          0|\n|          769|   1|        2.9|       1|  0|     0|         9|  0.1|      182|      5|  1|      248|     874|3946|   5|   2|        7|      0|           0|   0|          3|\n|         1520|   1|        2.2|       0|  5|     1|        33|  0.5|      177|      8| 18|      151|    1005|3826|  14|   9|       13|      1|           1|   1|          3|\n|         1815|   0|        2.8|       0|  2|     0|        33|  0.6|      159|      4| 17|      607|     748|1482|  18|   0|        2|      1|           0|   0|          1|\n|          803|   1|        2.1|       0|  7|     0|        17|  1.0|      198|      4| 11|      344|    1440|2680|   7|   1|        4|      1|           0|   1|          2|\n|         1866|   0|        0.5|       0| 13|     1|        52|  0.7|      185|      1| 17|      356|     563| 373|  14|   9|        3|      1|           0|   1|          0|\n|          775|   0|        1.0|       0|  3|     0|        46|  0.7|      159|      2| 16|      862|    1864| 568|  17|  15|       11|      1|           1|   1|          0|\n|          838|   0|        0.5|       0|  1|     1|        13|  0.1|      196|      8|  4|      984|    1850|3554|  10|   9|       19|      1|           0|   1|          3|\n|          595|   0|        0.9|       1|  7|     1|        23|  0.1|      121|      3| 17|      441|     810|3752|  10|   2|       18|      1|           1|   0|          3|\n|         1131|   1|        0.5|       1| 11|     0|        49|  0.6|      101|      5| 18|      658|     878|1835|  19|  13|       16|      1|           1|   0|          1|\n|          682|   1|        0.5|       0|  4|     0|        19|  1.0|      121|      4| 11|      902|    1064|2337|  11|   1|       18|      0|           1|   1|          1|\n+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.printSchema()",
            "execution_count": 146,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "root\n |-- battery_power: integer (nullable = true)\n |-- blue: integer (nullable = true)\n |-- clock_speed: double (nullable = true)\n |-- dual_sim: integer (nullable = true)\n |-- fc: integer (nullable = true)\n |-- four_g: integer (nullable = true)\n |-- int_memory: integer (nullable = true)\n |-- m_dep: double (nullable = true)\n |-- mobile_wt: integer (nullable = true)\n |-- n_cores: integer (nullable = true)\n |-- pc: integer (nullable = true)\n |-- px_height: integer (nullable = true)\n |-- px_width: integer (nullable = true)\n |-- ram: integer (nullable = true)\n |-- sc_h: integer (nullable = true)\n |-- sc_w: integer (nullable = true)\n |-- talk_time: integer (nullable = true)\n |-- three_g: integer (nullable = true)\n |-- touch_screen: integer (nullable = true)\n |-- wifi: integer (nullable = true)\n |-- price_range: integer (nullable = true)\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.createOrReplaceTempView('Dataset')",
            "execution_count": 147,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Initial Data Exploration\nNow, I am going to implement some simple functions that i learned earlier so that i can have a view of my dataset. I will find min, mix, standard deviation and some other properties of my data columns and will explore them on different columns. I have imported data using pandas dataframe but now converted it to spark and created a view so that i can run quries on it."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find minimum of a column\n\"\"\"\ndef findMin(columnName):\n    return spark.sql(\"SELECT min(battery_power) as minVal from Dataset\").first().minVal",
            "execution_count": 148,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find maximum of a column\n\"\"\"\ndef findMax(columnName):\n    return spark.sql('select max('+columnName+') as maxVal from Dataset').first().maxVal",
            "execution_count": 149,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find mean of a column\n\"\"\"\ndef findMean(columnName):\n    return spark.sql('select avg('+columnName+') as meanVal from Dataset').first().meanVal",
            "execution_count": 150,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find starndard deviation of a column\n\"\"\"\ndef findstdDev(columnName):\n    return spark.sql('select stddev('+columnName+') as stddev from Dataset').first().stddev",
            "execution_count": 151,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find skewness for a column\n\"\"\"\ndef findSkew(columnName):    \n    return spark.sql(\"\"\"\nSELECT \n    (\n        1/count(*)\n    ) *\n    SUM (\n        POWER(\"\"\"+columnName+\"\"\"-%s,3)/POWER(%s,3)\n    )\n    as skewVal\n from Dataset\n                    \"\"\" %(findMean(columnName),findstdDev(columnName))).first().skewVal\n",
            "execution_count": 152,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "minVal = findMin('battery_power')\nprint(minVal)",
            "execution_count": 155,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "501\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "findSkew('battery_power')",
            "execution_count": 156,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 156,
                    "data": {
                        "text/plain": "0.031850640034327575"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\"\"\"\n    function to find kurtosis for specific column\n\"\"\"\ndef kurtosis(columnName):    \n        return spark.sql(\"\"\"\nSELECT \n    (\n        1/count(*)\n    ) *\n    SUM (\n        POWER(\"\"\"+columnName+\"\"\"-%s,4)/POWER(%s,4)\n    )\nas kut\nfrom Dataset\n                    \"\"\" %(findMean(columnName),findstdDev(columnName))).first().kut\n",
            "execution_count": 157,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "kurtosis('battery_power')",
            "execution_count": 158,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 158,
                    "data": {
                        "text/plain": "1.7741403624192582"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def correlationinMobileWeightandBatteryPower():\n    return spark.sql(\"SELECT corr(battery_power,mobile_wt) as corrVal from Dataset\").first().corrVal",
            "execution_count": 159,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "correlationinMobileWeightandBatteryPower()",
            "execution_count": 160,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 160,
                    "data": {
                        "text/plain": "0.0018443762145708168"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Feature Creation\nAs i have checked and visualized data above. I would have loved to plot it using matplotlib.pyplot but as data has 21 dimensions so it is impossible to plot hyperdimension here. I have visualized data using different parameters. As i pbtained dataset from Kaggle and checked data. there was no need of big cleaning because data was not redundant or all the columns have values. There is null value in any cell. Now, it is time to create features and define model using sparkml"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\n\n\nvectorAssembler = VectorAssembler(inputCols=['battery_power','blue','clock_speed','dual_sim', 'fc','four_g',\n                                             'int_memory','m_dep','mobile_wt','n_cores', 'pc','px_height','px_width',\n                                             'ram','sc_h','sc_w','talk_time','three_g','touch_screen','wifi'], outputCol='features')\n\nnormalizer = Normalizer(inputCol='features', outputCol='features_normalized', p=1.0)",
            "execution_count": 183,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Creating ML Pipeline"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages =[vectorAssembler, normalizer])\n\nmodel = pipeline.fit(df)\n\nnew_df = model.transform(df)\n\nnew_df.show()",
            "execution_count": 184,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+--------------------+--------------------+\n|battery_power|blue|clock_speed|dual_sim| fc|four_g|int_memory|m_dep|mobile_wt|n_cores| pc|px_height|px_width| ram|sc_h|sc_w|talk_time|three_g|touch_screen|wifi|price_range|            features| features_normalized|\n+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+--------------------+--------------------+\n|          842|   0|        2.2|       0|  1|     0|         7|  0.6|      188|      2|  2|       20|     756|2549|   9|   7|       19|      0|           0|   1|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|\n|         1021|   1|        0.5|       1|  0|     1|        53|  0.7|      136|      3|  6|      905|    1988|2631|  17|   3|        7|      1|           1|   0|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|\n|          563|   1|        0.5|       1|  2|     1|        41|  0.9|      145|      5|  6|     1263|    1716|2603|  11|   2|        9|      1|           1|   0|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|\n|          615|   1|        2.5|       0|  0|     0|        10|  0.8|      131|      6|  9|     1216|    1786|2769|  16|   8|       11|      1|           0|   0|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|\n|         1821|   1|        1.2|       0| 13|     1|        44|  0.6|      141|      2| 14|     1208|    1212|1411|   8|   2|       15|      1|           1|   0|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|\n|         1859|   0|        0.5|       1|  3|     0|        22|  0.7|      164|      1|  7|     1004|    1654|1067|  17|   1|       10|      1|           0|   0|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|\n|         1821|   0|        1.7|       0|  4|     1|        10|  0.8|      139|      8| 10|      381|    1018|3220|  13|   8|       18|      1|           0|   1|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|\n|         1954|   0|        0.5|       1|  0|     0|        24|  0.8|      187|      4|  0|      512|    1149| 700|  16|   3|        5|      1|           1|   1|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...|\n|         1445|   1|        0.5|       0|  0|     0|        53|  0.7|      174|      7| 14|      386|     836|1099|  17|   1|       20|      1|           0|   0|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...|\n|          509|   1|        0.6|       1|  2|     1|         9|  0.1|       93|      5| 15|     1137|    1224| 513|  19|  10|       12|      1|           0|   0|          0|[509.0,1.0,0.6,1....|[0.14327131477467...|\n|          769|   1|        2.9|       1|  0|     0|         9|  0.1|      182|      5|  1|      248|     874|3946|   5|   2|        7|      0|           0|   0|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|\n|         1520|   1|        2.2|       0|  5|     1|        33|  0.5|      177|      8| 18|      151|    1005|3826|  14|   9|       13|      1|           1|   1|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|\n|         1815|   0|        2.8|       0|  2|     0|        33|  0.6|      159|      4| 17|      607|     748|1482|  18|   0|        2|      1|           0|   0|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...|\n|          803|   1|        2.1|       0|  7|     0|        17|  1.0|      198|      4| 11|      344|    1440|2680|   7|   1|        4|      1|           0|   1|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|\n|         1866|   0|        0.5|       0| 13|     1|        52|  0.7|      185|      1| 17|      356|     563| 373|  14|   9|        3|      1|           0|   1|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...|\n|          775|   0|        1.0|       0|  3|     0|        46|  0.7|      159|      2| 16|      862|    1864| 568|  17|  15|       11|      1|           1|   1|          0|[775.0,0.0,1.0,0....|[0.17846040481727...|\n|          838|   0|        0.5|       0|  1|     1|        13|  0.1|      196|      8|  4|      984|    1850|3554|  10|   9|       19|      1|           0|   1|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|\n|          595|   0|        0.9|       1|  7|     1|        23|  0.1|      121|      3| 17|      441|     810|3752|  10|   2|       18|      1|           1|   0|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|\n|         1131|   1|        0.5|       1| 11|     0|        49|  0.6|      101|      5| 18|      658|     878|1835|  19|  13|       16|      1|           1|   0|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...|\n|          682|   1|        0.5|       0|  4|     0|        19|  1.0|      121|      4| 11|      902|    1064|2337|  11|   1|       18|      0|           1|   1|          1|[682.0,1.0,0.5,0....|[0.13169836825335...|\n+-------------+----+-----------+--------+---+------+----------+-----+---------+-------+---+---------+--------+----+----+----+---------+-------+------------+----+-----------+--------------------+--------------------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Deleting useless columns\nthis now has become a big dataframe and i don't want that. I have created features and normalized. I have performed all of them using ML pipeline availabel in Apache spark. Now its time to delete that columns that i don't need\nLet's do it."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df2 = new_df.drop('battery_power').drop('blue').drop('clock_speed').drop('dual_sim').drop('fc')\\\n.drop('four_g').drop('int_memory').drop('m_dep').drop('mobile_wt').drop('n_cores').drop('pc')\\\n.drop('px_height').drop('px_width').drop('ram').drop('sc_h').drop('sc_w').drop('talk_time')\\\n.drop('three_g').drop('touch_screen').drop('wifi')",
            "execution_count": 185,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df2.show()",
            "execution_count": 186,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----------+--------------------+--------------------+\n|price_range|            features| features_normalized|\n+-----------+--------------------+--------------------+\n|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|\n|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|\n|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|\n|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|\n|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|\n|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|\n|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|\n|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...|\n|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...|\n|          0|[509.0,1.0,0.6,1....|[0.14327131477467...|\n|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|\n|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|\n|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...|\n|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|\n|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...|\n|          0|[775.0,0.0,1.0,0....|[0.17846040481727...|\n|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|\n|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|\n|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...|\n|          1|[682.0,1.0,0.5,0....|[0.13169836825335...|\n+-----------+--------------------+--------------------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Machine Learning Algorithms"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1. Decision Tree Classifier"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.classification import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier(featuresCol=\"features_normalized\", labelCol=\"price_range\")\n\nmodel = classifier.fit(df2)\n\nmodel = model.transform(df2)\n\nmodel.show()",
            "execution_count": 190,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|price_range|            features| features_normalized|       rawPrediction|         probability|prediction|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|  [10.0,8.0,0.0,0.0]|[0.55555555555555...|       0.0|\n|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|[0.0,7.0,40.0,365.0]|[0.0,0.0169902912...|       3.0|\n|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|[0.0,7.0,40.0,365.0]|[0.0,0.0169902912...|       3.0|\n|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|[0.0,7.0,40.0,365.0]|[0.0,0.0169902912...|       3.0|\n|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|[45.0,165.0,40.0,...|[0.18,0.66,0.16,0.0]|       1.0|\n|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|[45.0,165.0,40.0,...|[0.18,0.66,0.16,0.0]|       1.0|\n|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|[0.0,7.0,40.0,365.0]|[0.0,0.0169902912...|       3.0|\n|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...| [264.0,4.0,0.0,0.0]|[0.98507462686567...|       0.0|\n|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...| [264.0,4.0,0.0,0.0]|[0.98507462686567...|       0.0|\n|          0|[509.0,1.0,0.6,1....|[0.14327131477467...| [264.0,4.0,0.0,0.0]|[0.98507462686567...|       0.0|\n|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|[6.0,17.0,95.0,59.0]|[0.03389830508474...|       2.0|\n|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|[6.0,17.0,95.0,59.0]|[0.03389830508474...|       2.0|\n|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...| [9.0,155.0,7.0,0.0]|[0.05263157894736...|       1.0|\n|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|[0.0,6.0,182.0,19.0]|[0.0,0.0289855072...|       2.0|\n|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...| [264.0,4.0,0.0,0.0]|[0.98507462686567...|       0.0|\n|          0|[775.0,0.0,1.0,0....|[0.17846040481727...| [264.0,4.0,0.0,0.0]|[0.98507462686567...|       0.0|\n|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|[6.0,17.0,95.0,59.0]|[0.03389830508474...|       2.0|\n|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|[0.0,6.0,182.0,19.0]|[0.0,0.0289855072...|       2.0|\n|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...| [9.0,155.0,7.0,0.0]|[0.05263157894736...|       1.0|\n|          1|[682.0,1.0,0.5,0....|[0.13169836825335...| [0.0,7.0,23.0,13.0]|[0.0,0.1627906976...|       2.0|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"price_range\")\n    \nbinEval.evaluate(model) ",
            "execution_count": 193,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 193,
                    "data": {
                        "text/plain": "0.8115"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "df2.show()",
            "execution_count": 196,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----------+--------------------+--------------------+\n|price_range|            features| features_normalized|\n+-----------+--------------------+--------------------+\n|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|\n|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|\n|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|\n|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|\n|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|\n|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|\n|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|\n|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...|\n|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...|\n|          0|[509.0,1.0,0.6,1....|[0.14327131477467...|\n|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|\n|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|\n|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...|\n|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|\n|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...|\n|          0|[775.0,0.0,1.0,0....|[0.17846040481727...|\n|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|\n|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|\n|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...|\n|          1|[682.0,1.0,0.5,0....|[0.13169836825335...|\n+-----------+--------------------+--------------------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2. Random Forest Classifier"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.classification import RandomForestClassifier\n\nclassifier = RandomForestClassifier(featuresCol=\"features_normalized\", labelCol=\"price_range\")\n\nmodel1 = classifier.fit(df2)\n\nmodel1 = model1.transform(df2)\n\nmodel1.show()",
            "execution_count": 203,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|price_range|            features| features_normalized|       rawPrediction|         probability|prediction|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|[2.05613725543917...|[0.10280686277195...|       1.0|\n|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|[0.56028438564035...|[0.02801421928201...|       3.0|\n|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|[0.48607733553512...|[0.02430386677675...|       3.0|\n|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|[0.38257816842505...|[0.01912890842125...|       3.0|\n|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|[1.57970920595967...|[0.07898546029798...|       1.0|\n|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|[2.17233447955945...|[0.10861672397797...|       1.0|\n|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|[0.19377770406861...|[0.00968888520343...|       3.0|\n|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...|[14.8065747874208...|[0.74032873937104...|       0.0|\n|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...|[16.2652803583183...|[0.81326401791591...|       0.0|\n|          0|[509.0,1.0,0.6,1....|[0.14327131477467...|[18.1908779210762...|[0.90954389605381...|       0.0|\n|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|[0.34211190815647...|[0.01710559540782...|       3.0|\n|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|[0.22444099458244...|[0.01122204972912...|       3.0|\n|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...|[2.76326246696477...|[0.13816312334823...|       1.0|\n|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|[0.63410393786733...|[0.03170519689336...|       2.0|\n|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...|[19.0087637193539...|[0.95043818596769...|       0.0|\n|          0|[775.0,0.0,1.0,0....|[0.17846040481727...|[17.4836420452048...|[0.87418210226024...|       0.0|\n|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|[0.22444099458244...|[0.01122204972912...|       3.0|\n|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|[0.25067335461023...|[0.01253366773051...|       2.0|\n|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...|[3.93856034737368...|[0.19692801736868...|       1.0|\n|          1|[682.0,1.0,0.5,0....|[0.13169836825335...|[0.74740279278242...|[0.03737013963912...|       1.0|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"price_range\")\n    \nbinEval.evaluate(model1) ",
            "execution_count": 204,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 204,
                    "data": {
                        "text/plain": "0.8565"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3. Logistic Regression Classifier"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.classification import LogisticRegression\n\nclassifier =LogisticRegression(featuresCol=\"features_normalized\", labelCol=\"price_range\")\n\nmodel3 = classifier.fit(df2)\n\nmodel3 = model3.transform(df2)\n\nmodel3.show()",
            "execution_count": 206,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|price_range|            features| features_normalized|       rawPrediction|         probability|prediction|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\n|          1|[842.0,0.0,2.2,0....|[0.19111171637387...|[-4.6117991971757...|[3.25847702938626...|       2.0|\n|          2|[1021.0,1.0,0.5,1...|[0.15067441929104...|[-4.5399931399192...|[7.52007943914062...|       2.0|\n|          2|[563.0,1.0,0.5,1....|[0.08834975833281...|[-4.4826035856861...|[7.68929870609152...|       2.0|\n|          2|[615.0,1.0,2.5,0....|[0.09343238685565...|[-5.2814555859558...|[2.07710523953717...|       2.0|\n|          1|[1821.0,1.0,1.2,0...|[0.30881155881155...|[-1.3744837438914...|[0.01698546786883...|       1.0|\n|          1|[1859.0,0.0,0.5,1...|[0.31984446509067...|[0.74947976026659...|[0.08969699656940...|       1.0|\n|          3|[1821.0,0.0,1.7,0...|[0.27360829389226...|[-7.4192951706489...|[8.92548995701406...|       2.0|\n|          0|[1954.0,0.0,0.5,1...|[0.42857456188449...|[8.01030695789331...|[0.94389388120219...|       0.0|\n|          0|[1445.0,1.0,0.5,0...|[0.35633260998224...|[9.95757141657768...|[0.97342546365161...|       0.0|\n|          0|[509.0,1.0,0.6,1....|[0.14327131477467...|[9.85601367660999...|[0.99137313760089...|       0.0|\n|          3|[769.0,1.0,2.9,1....|[0.12704444077317...|[-12.834607697267...|[8.92559579946343...|       3.0|\n|          3|[1520.0,1.0,2.2,0...|[0.22396746577865...|[-6.5919688070994...|[3.23069605904178...|       2.0|\n|          1|[1815.0,0.0,2.8,0...|[0.37105941039375...|[1.72352981838710...|[0.15945126254136...|       1.0|\n|          2|[803.0,1.0,2.1,0....|[0.14541569330508...|[-3.6892297594189...|[0.00102896654154...|       2.0|\n|          0|[1866.0,0.0,0.5,0...|[0.53989931138244...|[12.6487530091609...|[0.99522353778067...|       0.0|\n|          0|[775.0,0.0,1.0,0....|[0.17846040481727...|[11.5771676920243...|[0.99661784198714...|       0.0|\n|          3|[838.0,0.0,0.5,0....|[0.11188848536637...|[-8.3225034184597...|[1.86848627892398...|       3.0|\n|          3|[595.0,0.0,0.9,1....|[0.10251550654720...|[-11.534644632624...|[6.88773317859848...|       3.0|\n|          1|[1131.0,1.0,0.5,1...|[0.23865290878014...|[1.09233435713229...|[0.09508357316782...|       1.0|\n|          1|[682.0,1.0,0.5,0....|[0.13169836825335...|[-4.2262136021411...|[9.95833331441926...|       2.0|\n+-----------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"price_range\")\n    \nbinEval.evaluate(model3) ",
            "execution_count": 207,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 207,
                    "data": {
                        "text/plain": "0.7605"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Accuracy Comparision between ML models\n\n### Decision Tree Classifier ==> 81.15 %\n### Random Forest Classifier ==> 85.65 %\n### Logistic Regression ==> 76.05 %\n\nby examining above evaluations i have found Random forest best working on this dataset and has more accuracy"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Deep Learning \nI am doing it using pytorch framework"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install torch torchvision",
            "execution_count": 209,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting torch\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n\u001b[K    100% |################################| 752.0MB 37kB/s  eta 0:00:01K    12% |###                             | 91.4MB 58.2MB/s eta 0:00:12    31% |##########                      | 237.9MB 56.7MB/s eta 0:00:10.5MB 58.4MB/s eta 0:00:09    40% |############                    | 302.1MB 47.5MB/s eta 0:00:10.3MB 55.3MB/s eta 0:00:07.9MB 65.8MB/s eta 0:00:06.8MB 66.9MB/s eta 0:00:03\n\u001b[?25hCollecting torchvision\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/51/aa2770a70f612ce9a2fc7da3a1a93f9ecf8746788256fed6b691f9b31ca9/torchvision-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n\u001b[K    100% |################################| 6.6MB 2.1MB/s eta 0:00:01\n\u001b[?25hCollecting numpy (from torch)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/fc/4763e5f17ac6e7e7d55f377cde859ca1c5d5ac624441ab45315bc578aa9e/numpy-1.18.3-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n\u001b[K    100% |################################| 20.2MB 900kB/s eta 0:00:01                                | 552kB 62.9MB/s eta 0:00:01\n\u001b[?25hCollecting future (from torch)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n\u001b[K    100% |################################| 829kB 4.0MB/s eta 0:00:01\n\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/90/8a24e6220cfcf6a3a0162535d5b926e774117e384ff921908e07e4c92bda/Pillow-7.1.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n\u001b[K    100% |################################| 2.1MB 3.4MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: future\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\nSuccessfully built future\n\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, future, torch, pillow, torchvision\nSuccessfully installed future-0.18.2 numpy-1.18.3 pillow-7.1.1 torch-1.5.0 torchvision-0.6.0\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Again taking our initial dataset in Pandas dataframe and converting it to pytorch tensor"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_data_1",
            "execution_count": 223,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 223,
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>battery_power</th>\n      <th>blue</th>\n      <th>clock_speed</th>\n      <th>dual_sim</th>\n      <th>fc</th>\n      <th>four_g</th>\n      <th>int_memory</th>\n      <th>m_dep</th>\n      <th>mobile_wt</th>\n      <th>n_cores</th>\n      <th>...</th>\n      <th>px_height</th>\n      <th>px_width</th>\n      <th>ram</th>\n      <th>sc_h</th>\n      <th>sc_w</th>\n      <th>talk_time</th>\n      <th>three_g</th>\n      <th>touch_screen</th>\n      <th>wifi</th>\n      <th>price_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.6</td>\n      <td>188</td>\n      <td>2</td>\n      <td>...</td>\n      <td>20</td>\n      <td>756</td>\n      <td>2549</td>\n      <td>9</td>\n      <td>7</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1021</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>136</td>\n      <td>3</td>\n      <td>...</td>\n      <td>905</td>\n      <td>1988</td>\n      <td>2631</td>\n      <td>17</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>563</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.9</td>\n      <td>145</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1263</td>\n      <td>1716</td>\n      <td>2603</td>\n      <td>11</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>615</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>131</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1216</td>\n      <td>1786</td>\n      <td>2769</td>\n      <td>16</td>\n      <td>8</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1821</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0.6</td>\n      <td>141</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1208</td>\n      <td>1212</td>\n      <td>1411</td>\n      <td>8</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1859</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0.7</td>\n      <td>164</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1004</td>\n      <td>1654</td>\n      <td>1067</td>\n      <td>17</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1821</td>\n      <td>0</td>\n      <td>1.7</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>139</td>\n      <td>8</td>\n      <td>...</td>\n      <td>381</td>\n      <td>1018</td>\n      <td>3220</td>\n      <td>13</td>\n      <td>8</td>\n      <td>18</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1954</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>0.8</td>\n      <td>187</td>\n      <td>4</td>\n      <td>...</td>\n      <td>512</td>\n      <td>1149</td>\n      <td>700</td>\n      <td>16</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1445</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>174</td>\n      <td>7</td>\n      <td>...</td>\n      <td>386</td>\n      <td>836</td>\n      <td>1099</td>\n      <td>17</td>\n      <td>1</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>509</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0.1</td>\n      <td>93</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1137</td>\n      <td>1224</td>\n      <td>513</td>\n      <td>19</td>\n      <td>10</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>769</td>\n      <td>1</td>\n      <td>2.9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.1</td>\n      <td>182</td>\n      <td>5</td>\n      <td>...</td>\n      <td>248</td>\n      <td>874</td>\n      <td>3946</td>\n      <td>5</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1520</td>\n      <td>1</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>33</td>\n      <td>0.5</td>\n      <td>177</td>\n      <td>8</td>\n      <td>...</td>\n      <td>151</td>\n      <td>1005</td>\n      <td>3826</td>\n      <td>14</td>\n      <td>9</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1815</td>\n      <td>0</td>\n      <td>2.8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0.6</td>\n      <td>159</td>\n      <td>4</td>\n      <td>...</td>\n      <td>607</td>\n      <td>748</td>\n      <td>1482</td>\n      <td>18</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>803</td>\n      <td>1</td>\n      <td>2.1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>17</td>\n      <td>1.0</td>\n      <td>198</td>\n      <td>4</td>\n      <td>...</td>\n      <td>344</td>\n      <td>1440</td>\n      <td>2680</td>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1866</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>52</td>\n      <td>0.7</td>\n      <td>185</td>\n      <td>1</td>\n      <td>...</td>\n      <td>356</td>\n      <td>563</td>\n      <td>373</td>\n      <td>14</td>\n      <td>9</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>775</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>46</td>\n      <td>0.7</td>\n      <td>159</td>\n      <td>2</td>\n      <td>...</td>\n      <td>862</td>\n      <td>1864</td>\n      <td>568</td>\n      <td>17</td>\n      <td>15</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>838</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0.1</td>\n      <td>196</td>\n      <td>8</td>\n      <td>...</td>\n      <td>984</td>\n      <td>1850</td>\n      <td>3554</td>\n      <td>10</td>\n      <td>9</td>\n      <td>19</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>595</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>23</td>\n      <td>0.1</td>\n      <td>121</td>\n      <td>3</td>\n      <td>...</td>\n      <td>441</td>\n      <td>810</td>\n      <td>3752</td>\n      <td>10</td>\n      <td>2</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1131</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0</td>\n      <td>49</td>\n      <td>0.6</td>\n      <td>101</td>\n      <td>5</td>\n      <td>...</td>\n      <td>658</td>\n      <td>878</td>\n      <td>1835</td>\n      <td>19</td>\n      <td>13</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>682</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>19</td>\n      <td>1.0</td>\n      <td>121</td>\n      <td>4</td>\n      <td>...</td>\n      <td>902</td>\n      <td>1064</td>\n      <td>2337</td>\n      <td>11</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>772</td>\n      <td>0</td>\n      <td>1.1</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0</td>\n      <td>39</td>\n      <td>0.8</td>\n      <td>81</td>\n      <td>7</td>\n      <td>...</td>\n      <td>1314</td>\n      <td>1854</td>\n      <td>2819</td>\n      <td>17</td>\n      <td>15</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1709</td>\n      <td>1</td>\n      <td>2.1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1.0</td>\n      <td>156</td>\n      <td>2</td>\n      <td>...</td>\n      <td>974</td>\n      <td>1385</td>\n      <td>3283</td>\n      <td>17</td>\n      <td>1</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1949</td>\n      <td>0</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>47</td>\n      <td>0.3</td>\n      <td>199</td>\n      <td>4</td>\n      <td>...</td>\n      <td>407</td>\n      <td>822</td>\n      <td>1433</td>\n      <td>11</td>\n      <td>5</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1602</td>\n      <td>1</td>\n      <td>2.8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>38</td>\n      <td>0.7</td>\n      <td>114</td>\n      <td>3</td>\n      <td>...</td>\n      <td>466</td>\n      <td>788</td>\n      <td>1037</td>\n      <td>8</td>\n      <td>7</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>503</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>8</td>\n      <td>0.4</td>\n      <td>111</td>\n      <td>3</td>\n      <td>...</td>\n      <td>201</td>\n      <td>1245</td>\n      <td>2583</td>\n      <td>11</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>961</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>57</td>\n      <td>0.6</td>\n      <td>114</td>\n      <td>8</td>\n      <td>...</td>\n      <td>291</td>\n      <td>1434</td>\n      <td>2782</td>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>519</td>\n      <td>1</td>\n      <td>1.6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>51</td>\n      <td>0.3</td>\n      <td>132</td>\n      <td>4</td>\n      <td>...</td>\n      <td>550</td>\n      <td>645</td>\n      <td>3763</td>\n      <td>16</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>956</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>143</td>\n      <td>7</td>\n      <td>...</td>\n      <td>511</td>\n      <td>1075</td>\n      <td>3286</td>\n      <td>17</td>\n      <td>8</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1453</td>\n      <td>0</td>\n      <td>1.6</td>\n      <td>1</td>\n      <td>12</td>\n      <td>1</td>\n      <td>52</td>\n      <td>0.3</td>\n      <td>96</td>\n      <td>2</td>\n      <td>...</td>\n      <td>187</td>\n      <td>1311</td>\n      <td>2373</td>\n      <td>10</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>851</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0.4</td>\n      <td>200</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1171</td>\n      <td>1263</td>\n      <td>478</td>\n      <td>12</td>\n      <td>7</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1970</th>\n      <td>1913</td>\n      <td>1</td>\n      <td>1.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>0.6</td>\n      <td>111</td>\n      <td>5</td>\n      <td>...</td>\n      <td>675</td>\n      <td>742</td>\n      <td>2023</td>\n      <td>17</td>\n      <td>13</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1971</th>\n      <td>538</td>\n      <td>0</td>\n      <td>1.1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>25</td>\n      <td>0.3</td>\n      <td>163</td>\n      <td>7</td>\n      <td>...</td>\n      <td>455</td>\n      <td>537</td>\n      <td>2215</td>\n      <td>9</td>\n      <td>3</td>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1972</th>\n      <td>1191</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>46</td>\n      <td>0.8</td>\n      <td>89</td>\n      <td>6</td>\n      <td>...</td>\n      <td>42</td>\n      <td>807</td>\n      <td>824</td>\n      <td>19</td>\n      <td>18</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1973</th>\n      <td>816</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.1</td>\n      <td>117</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1196</td>\n      <td>1651</td>\n      <td>3851</td>\n      <td>10</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>915</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>33</td>\n      <td>0.3</td>\n      <td>199</td>\n      <td>2</td>\n      <td>...</td>\n      <td>503</td>\n      <td>986</td>\n      <td>2156</td>\n      <td>7</td>\n      <td>3</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1975</th>\n      <td>1157</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>27</td>\n      <td>0.1</td>\n      <td>88</td>\n      <td>8</td>\n      <td>...</td>\n      <td>1694</td>\n      <td>1798</td>\n      <td>2885</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>1201</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>99</td>\n      <td>7</td>\n      <td>...</td>\n      <td>306</td>\n      <td>558</td>\n      <td>495</td>\n      <td>15</td>\n      <td>6</td>\n      <td>14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>1379</td>\n      <td>0</td>\n      <td>1.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0.2</td>\n      <td>129</td>\n      <td>2</td>\n      <td>...</td>\n      <td>838</td>\n      <td>885</td>\n      <td>2358</td>\n      <td>10</td>\n      <td>5</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1978</th>\n      <td>1483</td>\n      <td>1</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>169</td>\n      <td>5</td>\n      <td>...</td>\n      <td>291</td>\n      <td>651</td>\n      <td>1744</td>\n      <td>6</td>\n      <td>3</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1979</th>\n      <td>1614</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0.1</td>\n      <td>161</td>\n      <td>3</td>\n      <td>...</td>\n      <td>173</td>\n      <td>1219</td>\n      <td>1832</td>\n      <td>15</td>\n      <td>8</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1980</th>\n      <td>930</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.9</td>\n      <td>144</td>\n      <td>8</td>\n      <td>...</td>\n      <td>1017</td>\n      <td>1289</td>\n      <td>2016</td>\n      <td>13</td>\n      <td>10</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1981</th>\n      <td>1454</td>\n      <td>0</td>\n      <td>2.6</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0.4</td>\n      <td>199</td>\n      <td>3</td>\n      <td>...</td>\n      <td>698</td>\n      <td>1018</td>\n      <td>1300</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1982</th>\n      <td>1784</td>\n      <td>0</td>\n      <td>1.6</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>41</td>\n      <td>0.4</td>\n      <td>164</td>\n      <td>6</td>\n      <td>...</td>\n      <td>610</td>\n      <td>1437</td>\n      <td>2313</td>\n      <td>14</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1983</th>\n      <td>1262</td>\n      <td>0</td>\n      <td>1.8</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0</td>\n      <td>34</td>\n      <td>0.1</td>\n      <td>149</td>\n      <td>5</td>\n      <td>...</td>\n      <td>223</td>\n      <td>737</td>\n      <td>3248</td>\n      <td>13</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1984</th>\n      <td>797</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>0.9</td>\n      <td>144</td>\n      <td>7</td>\n      <td>...</td>\n      <td>206</td>\n      <td>1167</td>\n      <td>2216</td>\n      <td>9</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1985</th>\n      <td>1829</td>\n      <td>1</td>\n      <td>2.1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>59</td>\n      <td>0.1</td>\n      <td>91</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1457</td>\n      <td>1919</td>\n      <td>3142</td>\n      <td>16</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>1139</td>\n      <td>1</td>\n      <td>0.9</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>58</td>\n      <td>0.5</td>\n      <td>161</td>\n      <td>2</td>\n      <td>...</td>\n      <td>742</td>\n      <td>999</td>\n      <td>1850</td>\n      <td>9</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <td>618</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0.1</td>\n      <td>80</td>\n      <td>4</td>\n      <td>...</td>\n      <td>591</td>\n      <td>724</td>\n      <td>1424</td>\n      <td>15</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1988</th>\n      <td>1547</td>\n      <td>1</td>\n      <td>2.9</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>57</td>\n      <td>0.4</td>\n      <td>114</td>\n      <td>1</td>\n      <td>...</td>\n      <td>347</td>\n      <td>957</td>\n      <td>1620</td>\n      <td>9</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>586</td>\n      <td>0</td>\n      <td>2.8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0.2</td>\n      <td>83</td>\n      <td>3</td>\n      <td>...</td>\n      <td>241</td>\n      <td>854</td>\n      <td>2592</td>\n      <td>12</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>1617</td>\n      <td>1</td>\n      <td>2.4</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0.8</td>\n      <td>85</td>\n      <td>1</td>\n      <td>...</td>\n      <td>743</td>\n      <td>1426</td>\n      <td>296</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1991</th>\n      <td>1882</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0.8</td>\n      <td>113</td>\n      <td>8</td>\n      <td>...</td>\n      <td>4</td>\n      <td>743</td>\n      <td>3579</td>\n      <td>19</td>\n      <td>8</td>\n      <td>20</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>674</td>\n      <td>1</td>\n      <td>2.9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0.2</td>\n      <td>198</td>\n      <td>3</td>\n      <td>...</td>\n      <td>576</td>\n      <td>1809</td>\n      <td>1180</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>1467</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0.6</td>\n      <td>122</td>\n      <td>5</td>\n      <td>...</td>\n      <td>888</td>\n      <td>1099</td>\n      <td>3962</td>\n      <td>15</td>\n      <td>11</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>858</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>50</td>\n      <td>0.1</td>\n      <td>84</td>\n      <td>1</td>\n      <td>...</td>\n      <td>528</td>\n      <td>1416</td>\n      <td>3978</td>\n      <td>17</td>\n      <td>16</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>794</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.8</td>\n      <td>106</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1222</td>\n      <td>1890</td>\n      <td>668</td>\n      <td>13</td>\n      <td>4</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1965</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>39</td>\n      <td>0.2</td>\n      <td>187</td>\n      <td>4</td>\n      <td>...</td>\n      <td>915</td>\n      <td>1965</td>\n      <td>2032</td>\n      <td>11</td>\n      <td>10</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1911</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0.7</td>\n      <td>108</td>\n      <td>8</td>\n      <td>...</td>\n      <td>868</td>\n      <td>1632</td>\n      <td>3057</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1512</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>46</td>\n      <td>0.1</td>\n      <td>145</td>\n      <td>5</td>\n      <td>...</td>\n      <td>336</td>\n      <td>670</td>\n      <td>869</td>\n      <td>18</td>\n      <td>10</td>\n      <td>19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>510</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>45</td>\n      <td>0.9</td>\n      <td>168</td>\n      <td>6</td>\n      <td>...</td>\n      <td>483</td>\n      <td>754</td>\n      <td>3919</td>\n      <td>19</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows \u00d7 21 columns</p>\n</div>",
                        "text/plain": "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n0               842     0          2.2         0   1       0           7   \n1              1021     1          0.5         1   0       1          53   \n2               563     1          0.5         1   2       1          41   \n3               615     1          2.5         0   0       0          10   \n4              1821     1          1.2         0  13       1          44   \n5              1859     0          0.5         1   3       0          22   \n6              1821     0          1.7         0   4       1          10   \n7              1954     0          0.5         1   0       0          24   \n8              1445     1          0.5         0   0       0          53   \n9               509     1          0.6         1   2       1           9   \n10              769     1          2.9         1   0       0           9   \n11             1520     1          2.2         0   5       1          33   \n12             1815     0          2.8         0   2       0          33   \n13              803     1          2.1         0   7       0          17   \n14             1866     0          0.5         0  13       1          52   \n15              775     0          1.0         0   3       0          46   \n16              838     0          0.5         0   1       1          13   \n17              595     0          0.9         1   7       1          23   \n18             1131     1          0.5         1  11       0          49   \n19              682     1          0.5         0   4       0          19   \n20              772     0          1.1         1  12       0          39   \n21             1709     1          2.1         0   1       0          13   \n22             1949     0          2.6         1   4       0          47   \n23             1602     1          2.8         1   4       1          38   \n24              503     0          1.2         1   5       1           8   \n25              961     1          1.4         1   0       1          57   \n26              519     1          1.6         1   7       1          51   \n27              956     0          0.5         0   1       1          41   \n28             1453     0          1.6         1  12       1          52   \n29              851     0          0.5         0   3       0          21   \n...             ...   ...          ...       ...  ..     ...         ...   \n1970           1913     1          1.8         0   0       0          29   \n1971            538     0          1.1         1   0       1          25   \n1972           1191     0          0.8         0   6       1          46   \n1973            816     0          3.0         1   2       0           9   \n1974            915     1          0.5         1   9       1          33   \n1975           1157     1          0.8         0   7       0          27   \n1976           1201     1          0.5         0   2       0          10   \n1977           1379     0          1.1         1   1       1          18   \n1978           1483     1          2.2         0   3       1          53   \n1979           1614     0          1.2         0   1       1           9   \n1980            930     1          1.0         1   4       1           4   \n1981           1454     0          2.6         0   8       0           6   \n1982           1784     0          1.6         0   4       0          41   \n1983           1262     0          1.8         1  12       0          34   \n1984            797     0          2.2         1   0       0          37   \n1985           1829     1          2.1         0   8       0          59   \n1986           1139     1          0.9         1   6       1          58   \n1987            618     1          1.0         0   9       1          13   \n1988           1547     1          2.9         0   2       0          57   \n1989            586     0          2.8         0   2       0          15   \n1990           1617     1          2.4         0   8       1          36   \n1991           1882     0          2.0         0  11       1          44   \n1992            674     1          2.9         1   1       0          21   \n1993           1467     1          0.5         0   0       0          18   \n1994            858     0          2.2         0   1       0          50   \n1995            794     1          0.5         1   0       1           2   \n1996           1965     1          2.6         1   0       0          39   \n1997           1911     0          0.9         1   1       1          36   \n1998           1512     0          0.9         0   4       1          46   \n1999            510     1          2.0         1   5       1          45   \n\n      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n0       0.6        188        2  ...         20       756  2549     9     7   \n1       0.7        136        3  ...        905      1988  2631    17     3   \n2       0.9        145        5  ...       1263      1716  2603    11     2   \n3       0.8        131        6  ...       1216      1786  2769    16     8   \n4       0.6        141        2  ...       1208      1212  1411     8     2   \n5       0.7        164        1  ...       1004      1654  1067    17     1   \n6       0.8        139        8  ...        381      1018  3220    13     8   \n7       0.8        187        4  ...        512      1149   700    16     3   \n8       0.7        174        7  ...        386       836  1099    17     1   \n9       0.1         93        5  ...       1137      1224   513    19    10   \n10      0.1        182        5  ...        248       874  3946     5     2   \n11      0.5        177        8  ...        151      1005  3826    14     9   \n12      0.6        159        4  ...        607       748  1482    18     0   \n13      1.0        198        4  ...        344      1440  2680     7     1   \n14      0.7        185        1  ...        356       563   373    14     9   \n15      0.7        159        2  ...        862      1864   568    17    15   \n16      0.1        196        8  ...        984      1850  3554    10     9   \n17      0.1        121        3  ...        441       810  3752    10     2   \n18      0.6        101        5  ...        658       878  1835    19    13   \n19      1.0        121        4  ...        902      1064  2337    11     1   \n20      0.8         81        7  ...       1314      1854  2819    17    15   \n21      1.0        156        2  ...        974      1385  3283    17     1   \n22      0.3        199        4  ...        407       822  1433    11     5   \n23      0.7        114        3  ...        466       788  1037     8     7   \n24      0.4        111        3  ...        201      1245  2583    11     0   \n25      0.6        114        8  ...        291      1434  2782    18     9   \n26      0.3        132        4  ...        550       645  3763    16     1   \n27      1.0        143        7  ...        511      1075  3286    17     8   \n28      0.3         96        2  ...        187      1311  2373    10     1   \n29      0.4        200        5  ...       1171      1263   478    12     7   \n...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n1970    0.6        111        5  ...        675       742  2023    17    13   \n1971    0.3        163        7  ...        455       537  2215     9     3   \n1972    0.8         89        6  ...         42       807   824    19    18   \n1973    0.1        117        1  ...       1196      1651  3851    10     3   \n1974    0.3        199        2  ...        503       986  2156     7     3   \n1975    0.1         88        8  ...       1694      1798  2885     8     4   \n1976    1.0         99        7  ...        306       558   495    15     6   \n1977    0.2        129        2  ...        838       885  2358    10     5   \n1978    0.7        169        5  ...        291       651  1744     6     3   \n1979    0.1        161        3  ...        173      1219  1832    15     8   \n1980    0.9        144        8  ...       1017      1289  2016    13    10   \n1981    0.4        199        3  ...        698      1018  1300    10     0   \n1982    0.4        164        6  ...        610      1437  2313    14     1   \n1983    0.1        149        5  ...        223       737  3248    13     3   \n1984    0.9        144        7  ...        206      1167  2216     9     5   \n1985    0.1         91        5  ...       1457      1919  3142    16     6   \n1986    0.5        161        2  ...        742       999  1850     9     4   \n1987    0.1         80        4  ...        591       724  1424    15    12   \n1988    0.4        114        1  ...        347       957  1620     9     2   \n1989    0.2         83        3  ...        241       854  2592    12     8   \n1990    0.8         85        1  ...        743      1426   296     5     3   \n1991    0.8        113        8  ...          4       743  3579    19     8   \n1992    0.2        198        3  ...        576      1809  1180     6     3   \n1993    0.6        122        5  ...        888      1099  3962    15    11   \n1994    0.1         84        1  ...        528      1416  3978    17    16   \n1995    0.8        106        6  ...       1222      1890   668    13     4   \n1996    0.2        187        4  ...        915      1965  2032    11    10   \n1997    0.7        108        8  ...        868      1632  3057     9     1   \n1998    0.1        145        5  ...        336       670   869    18    10   \n1999    0.9        168        6  ...        483       754  3919    19     4   \n\n      talk_time  three_g  touch_screen  wifi  price_range  \n0            19        0             0     1            1  \n1             7        1             1     0            2  \n2             9        1             1     0            2  \n3            11        1             0     0            2  \n4            15        1             1     0            1  \n5            10        1             0     0            1  \n6            18        1             0     1            3  \n7             5        1             1     1            0  \n8            20        1             0     0            0  \n9            12        1             0     0            0  \n10            7        0             0     0            3  \n11           13        1             1     1            3  \n12            2        1             0     0            1  \n13            4        1             0     1            2  \n14            3        1             0     1            0  \n15           11        1             1     1            0  \n16           19        1             0     1            3  \n17           18        1             1     0            3  \n18           16        1             1     0            1  \n19           18        0             1     1            1  \n20            3        1             1     0            3  \n21           15        1             0     0            3  \n22           20        0             0     1            1  \n23           20        1             0     0            0  \n24           12        1             0     0            1  \n25            7        1             1     1            2  \n26            4        1             0     1            3  \n27           12        1             1     0            3  \n28           10        1             1     1            2  \n29           10        1             0     1            0  \n...         ...      ...           ...   ...          ...  \n1970          8        1             1     0            2  \n1971         17        1             1     1            1  \n1972          7        1             0     0            0  \n1973         14        1             0     1            3  \n1974         13        1             1     0            1  \n1975          2        1             0     1            3  \n1976         14        1             1     1            0  \n1977         15        1             1     0            2  \n1978         10        1             0     0            1  \n1979         11        1             0     0            1  \n1980         16        1             1     1            1  \n1981          2        0             0     1            1  \n1982         11        0             1     0            2  \n1983          4        0             1     1            2  \n1984          6        1             0     0            1  \n1985          5        1             1     1            3  \n1986          8        1             0     0            1  \n1987          7        1             1     0            0  \n1988         19        0             1     1            1  \n1989          3        0             0     0            1  \n1990          7        1             0     0            0  \n1991         20        1             1     0            3  \n1992          4        1             1     1            0  \n1993          5        1             1     1            3  \n1994          3        1             1     0            3  \n1995         19        1             1     0            0  \n1996         16        1             1     1            2  \n1997          5        1             1     0            3  \n1998         19        1             1     1            0  \n1999          2        1             1     1            3  \n\n[2000 rows x 21 columns]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F",
            "execution_count": 224,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "label_df = df_data_1['price_range']\ndf_train_new = df_data_1.drop(labels='price_range', axis=1)\n\ntrain_data = torch.tensor(df_train_new.values)\nprint(train_data.shape)\n\ntrain_label = torch.tensor(label_df.values)\ntrain_label",
            "execution_count": 227,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "torch.Size([2000, 20])\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 227,
                    "data": {
                        "text/plain": "tensor([1, 2, 2,  ..., 3, 0, 3])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "class Classifier(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.layer1 = nn.Linear(20,15)\n        self.layer2 = nn.Linear(15,8)\n        self.layer3 = nn.Linear(8,4)\n    \n    def forward(self,x):\n        \n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        \n        return x",
            "execution_count": 236,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "model = Classifier()\n\noptimizer = optim.SGD(model.parameters(), lr=0.005)\n\ncriterian = nn.CrossEntropyLoss()\n\ntrain_data = train_data.float()\ntrain_lable = train_label.float()\n\nepoch = 200\nfor i in range(epoch):\n    \n    optimizer.zero_grad()\n    output = model(train_data)\n    loss = criterian(output,train_label)\n    loss.backward()\n    optimizer.step()\n    \n    print('At ',i,'/100 epoch loss is: ',loss.item())",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "At  0 /100 epoch loss is:  146.50144958496094\nAt  1 /100 epoch loss is:  1192.158203125\nAt  2 /100 epoch loss is:  32.88018798828125\nAt  3 /100 epoch loss is:  1.7925831079483032\nAt  4 /100 epoch loss is:  1.7575114965438843\nAt  5 /100 epoch loss is:  1.7265074253082275\nAt  6 /100 epoch loss is:  1.7000300884246826\nAt  7 /100 epoch loss is:  1.676580548286438\nAt  8 /100 epoch loss is:  1.6549211740493774\nAt  9 /100 epoch loss is:  1.6349304914474487\nAt  10 /100 epoch loss is:  1.616404414176941\nAt  11 /100 epoch loss is:  1.599343180656433\nAt  12 /100 epoch loss is:  1.5836085081100464\nAt  13 /100 epoch loss is:  1.5691335201263428\nAt  14 /100 epoch loss is:  1.5557527542114258\nAt  15 /100 epoch loss is:  1.5434727668762207\nAt  16 /100 epoch loss is:  1.5321037769317627\nAt  17 /100 epoch loss is:  1.521689772605896\nAt  18 /100 epoch loss is:  1.5120354890823364\nAt  19 /100 epoch loss is:  1.5032122135162354\nAt  20 /100 epoch loss is:  1.4950437545776367\nAt  21 /100 epoch loss is:  1.4875407218933105\nAt  22 /100 epoch loss is:  1.4806156158447266\nAt  23 /100 epoch loss is:  1.4742170572280884\nAt  24 /100 epoch loss is:  1.468349575996399\nAt  25 /100 epoch loss is:  1.4629088640213013\nAt  26 /100 epoch loss is:  1.4579066038131714\nAt  27 /100 epoch loss is:  1.4532636404037476\nAt  28 /100 epoch loss is:  1.4490513801574707\nAt  29 /100 epoch loss is:  1.445088505744934\nAt  30 /100 epoch loss is:  1.4414281845092773\nAt  31 /100 epoch loss is:  1.4380742311477661\nAt  32 /100 epoch loss is:  1.434967279434204\nAt  33 /100 epoch loss is:  1.4320850372314453\nAt  34 /100 epoch loss is:  1.4294230937957764\nAt  35 /100 epoch loss is:  1.4269378185272217\nAt  36 /100 epoch loss is:  1.4246875047683716\nAt  37 /100 epoch loss is:  1.4225519895553589\nAt  38 /100 epoch loss is:  1.4205998182296753\nAt  39 /100 epoch loss is:  1.4187564849853516\nAt  40 /100 epoch loss is:  1.4170751571655273\nAt  41 /100 epoch loss is:  1.4156745672225952\nAt  42 /100 epoch loss is:  1.4151496887207031\nAt  43 /100 epoch loss is:  1.4146113395690918\nAt  44 /100 epoch loss is:  1.4140965938568115\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python36",
            "display_name": "Python 3.6 with Spark",
            "language": "python3"
        },
        "language_info": {
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "name": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8",
            "file_extension": ".py",
            "codemirror_mode": {
                "version": 3,
                "name": "ipython"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}